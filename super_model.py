import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import recall_score, precision_score
import warnings
warnings.filterwarnings('ignore')

def create_super_features(df):
    """Crear TODAS las caracter√≠sticas cr√≠ticas del an√°lisis profundo"""
    
    print("üîß CREANDO CARACTER√çSTICAS S√öPER CR√çTICAS...")
    
    data = df.copy()
    data['Created Date'] = pd.to_datetime(data['Created Date'], errors='coerce')
    
    # TEMPORALES CR√çTICAS
    data['Hour'] = data['Created Date'].dt.hour
    data['DayOfWeek'] = data['Created Date'].dt.dayofweek
    data['Month'] = data['Created Date'].dt.month
    
    # Horas M√ÅS cr√≠ticas (del an√°lisis profundo)
    data['Is_Hour_2AM'] = (data['Hour'] == 2).astype(int)     # 20.0% cr√≠ticos
    data['Is_Hour_5AM'] = (data['Hour'] == 5).astype(int)     # 18.8% cr√≠ticos  
    data['Is_Hour_Midnight'] = (data['Hour'] == 0).astype(int) # 18.6% cr√≠ticos
    data['Is_Madrugada'] = data['Hour'].between(0, 6).astype(int)
    
    # GEOGR√ÅFICAS CR√çTICAS
    data['Is_Bronx'] = (data['Borough'] == 'BRONX').astype(int)      # 20.2% cr√≠ticos
    data['Is_Brooklyn'] = (data['Borough'] == 'BROOKLYN').astype(int) # 18.0% cr√≠ticos
    
    # LOCATION TYPE CR√çTICO (¬°LA DIFERENCIA CLAVE!)
    data['Is_Park'] = (data['Location Type'] == 'Park/Playground').astype(int)    # 30.0% cr√≠ticos!!!
    data['Is_Subway'] = (data['Location Type'] == 'Subway Station').astype(int)   # 22.5% cr√≠ticos
    data['Is_Street'] = (data['Location Type'] == 'Street/Sidewalk').astype(int)  # 22.2% cr√≠ticos
    
    # INTERACCIONES S√öPER CR√çTICAS
    data['Bronx_Park'] = (data['Is_Bronx'] & data['Is_Park']).astype(int)
    data['Park_Madrugada'] = (data['Is_Park'] & data['Is_Madrugada']).astype(int)
    data['Bronx_Madrugada'] = (data['Is_Bronx'] & data['Is_Madrugada']).astype(int)
    
    # OTRAS
    data['Has_Coordinates'] = (~data['Latitude'].isna()).astype(int)
    
    print("‚úì Horas cr√≠ticas: 2AM, 5AM, Midnight, Madrugada")
    print("‚úì Boroughs cr√≠ticos: Bronx, Brooklyn")  
    print("‚úì Locations cr√≠ticos: Park (30%), Subway (22.5%), Street (22.2%)")
    print("‚úì Interacciones: Bronx+Park, Park+Madrugada, Bronx+Madrugada")
    
    return data

def main():
    print("=" * 60)
    print("MODELO S√öPER AVANZADO - CARACTER√çSTICAS CR√çTICAS")
    print("=" * 60)
    print("üéØ Objetivo: Maximizar detecci√≥n de casos cr√≠ticos")
    
    # 1. Datos
    binary_mapping = {
        'Tortured': 'CRITICO',
        'Chained': 'CRITICO',
        'Neglected': 'NO_CRITICO',
        'No Shelter': 'NO_CRITICO',
        'In Car': 'NO_CRITICO',
        'Noise, Barking Dog (NR5)': 'NO_CRITICO',
        'Other (complaint details)': 'NO_CRITICO'
    }
    
    df = pd.read_csv('Animal_Abuse.csv/Animal_Abuse.csv')
    df['Priority'] = df['Descriptor'].map(binary_mapping)
    
    print(f"\n1. DATOS: {len(df):,} filas")
    priority_counts = df['Priority'].value_counts()
    print(f"   CRITICO: {priority_counts['CRITICO']:,} ({priority_counts['CRITICO']/len(df)*100:.1f}%)")
    
    # 2. Caracter√≠sticas s√∫per cr√≠ticas
    print("\n2. CARACTER√çSTICAS S√öPER CR√çTICAS...")
    data = create_super_features(df)
    
    # Caracter√≠sticas finales
    features = [
        'Hour', 'DayOfWeek', 'Month',
        'Is_Hour_2AM', 'Is_Hour_5AM', 'Is_Hour_Midnight', 'Is_Madrugada',
        'Is_Bronx', 'Is_Brooklyn',
        'Is_Park', 'Is_Subway', 'Is_Street',
        'Bronx_Park', 'Park_Madrugada', 'Bronx_Madrugada',
        'Has_Coordinates'
    ]
    
    model_data = data[features + ['Priority']].dropna(subset=['Priority'])
    X = model_data[features]
    y = model_data['Priority']
    
    print(f"\n‚úì {len(features)} caracter√≠sticas seleccionadas")
    print(f"‚úì Dataset final: {len(model_data):,} filas")
    
    # Estad√≠sticas clave
    print(f"\nüìä ESTAD√çSTICAS CLAVE:")
    print(f"   Parks: {X['Is_Park'].sum():,} casos")
    print(f"   Bronx: {X['Is_Bronx'].sum():,} casos")
    print(f"   Madrugada: {X['Is_Madrugada'].sum():,} casos")
    print(f"   Bronx+Park: {X['Bronx_Park'].sum():,} casos")
    
    # 3. Divisi√≥n
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # 4. Modelos s√∫per optimizados
    print("\n3. MODELOS S√öPER OPTIMIZADOS...")
    
    models = {
        'S√∫per Cr√≠tico': RandomForestClassifier(
            n_estimators=400, max_depth=25, min_samples_split=2,
            class_weight={'CRITICO': 4.0, 'NO_CRITICO': 0.5},
            random_state=42, n_jobs=-1
        ),
        'Ultra Cr√≠tico': RandomForestClassifier(
            n_estimators=500, max_depth=30, min_samples_split=2,
            class_weight={'CRITICO': 5.0, 'NO_CRITICO': 0.4},
            max_features='sqrt', random_state=42, n_jobs=-1
        ),
        'Mega Cr√≠tico': RandomForestClassifier(
            n_estimators=600, max_depth=35, min_samples_split=2,
            class_weight={'CRITICO': 6.0, 'NO_CRITICO': 0.3},
            max_features=0.8, random_state=42, n_jobs=-1
        )
    }
    
    # Pipeline
    preprocessor = Pipeline([
        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),
        ('scaler', StandardScaler())
    ])
    
    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)
    
    results = {}
    
    for name, model in models.items():
        print(f"\nüîÑ Entrenando {name}...")
        
        model.fit(X_train_processed, y_train)
        y_pred = model.predict(X_test_processed)
        
        accuracy = accuracy_score(y_test, y_pred)
        f1_weighted = f1_score(y_test, y_pred, average='weighted')
        recall_critico = recall_score(y_test, y_pred, pos_label='CRITICO')
        f1_critico = f1_score(y_test, y_pred, pos_label='CRITICO')
        
        results[name] = {
            'model': model,
            'accuracy': accuracy,
            'f1_weighted': f1_weighted,
            'recall_critico': recall_critico,
            'f1_critico': f1_critico,
            'predictions': y_pred
        }
        
        print(f"   Accuracy: {accuracy*100:.1f}%")
        print(f"   F1-weighted: {f1_weighted*100:.1f}%")
        print(f"   Recall-CR√çTICO: {recall_critico*100:.1f}%")
    
    # 5. Mejor modelo
    print("\n4. MEJOR MODELO S√öPER CR√çTICO...")
    
    # Score que balancea accuracy y recall cr√≠tico
    def super_score(result):
        if result['accuracy'] < 0.5:
            return 0
        return 0.5 * result['accuracy'] + 0.5 * result['recall_critico']
    
    best_name = max(results.keys(), key=lambda x: super_score(results[x]))
    best = results[best_name]
    
    print(f"üèÜ MEJOR MODELO: {best_name}")
    print(f"   Accuracy: {best['accuracy']*100:.1f}%")
    print(f"   F1-weighted: {best['f1_weighted']*100:.1f}%")
    print(f"   Recall-CR√çTICO: {best['recall_critico']*100:.1f}%")
    print(f"   F1-CR√çTICO: {best['f1_critico']*100:.1f}%")
    
    # An√°lisis de casos cr√≠ticos
    y_pred_best = best['predictions']
    cm = confusion_matrix(y_test, y_pred_best, labels=['CRITICO', 'NO_CRITICO'])
    criticos_reales = sum(y_test == 'CRITICO')
    criticos_detectados = cm[0, 0]
    
    print(f"\nüéØ CASOS CR√çTICOS:")
    print(f"   Total: {criticos_reales:,}")
    print(f"   Detectados: {criticos_detectados:,}")
    print(f"   Perdidos: {criticos_reales - criticos_detectados:,}")
    print(f"   Tasa detecci√≥n: {criticos_detectados/criticos_reales*100:.1f}%")
    
    # Importancia de caracter√≠sticas
    importances = best['model'].feature_importances_
    feature_importance = pd.DataFrame({
        'Feature': features,
        'Importance': importances
    }).sort_values('Importance', ascending=False)
    
    print(f"\nüéØ TOP 5 CARACTER√çSTICAS:")
    for i, row in feature_importance.head(5).iterrows():
        print(f"   {row['Feature']}: {row['Importance']:.4f}")
    
    # 6. Visualizaci√≥n s√∫per
    print("\n5. VISUALIZACI√ìN S√öPER...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Comparaci√≥n de modelos
    names = list(results.keys())
    accs = [results[name]['accuracy'] for name in names]
    recalls = [results[name]['recall_critico'] for name in names]
    
    x = np.arange(len(names))
    width = 0.35
    
    axes[0, 0].bar(x - width/2, accs, width, label='Accuracy', alpha=0.8)
    axes[0, 0].bar(x + width/2, recalls, width, label='Recall Cr√≠tico', alpha=0.8)
    axes[0, 0].set_title('Modelos S√∫per Cr√≠ticos')
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(names)
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # Matriz de confusi√≥n
    sns.heatmap(cm, annot=True, fmt='d', ax=axes[0, 1], cmap='Reds',
                xticklabels=['CR√çTICO', 'NO CR√çTICO'],
                yticklabels=['CR√çTICO', 'NO CR√çTICO'])
    axes[0, 1].set_title(f'Matriz de Confusi√≥n\n{best_name}')
    
    # Evoluci√≥n COMPLETA del proyecto
    evolution = [
        ('Original\n(7 clases)', 0.5652, 0),
        ('Binario\nSimple', 0.8246, 33),
        ('Binario\nBalanceado', 0.8071, 144),
        ('S√∫per\nAvanzado', best['accuracy'], criticos_detectados)
    ]
    
    model_names = [x[0] for x in evolution]
    accuracies = [x[1] for x in evolution]
    casos = [x[2] for x in evolution]
    
    # Accuracy
    axes[1, 0].bar(model_names, accuracies, color='blue', alpha=0.7)
    axes[1, 0].set_title('Evoluci√≥n de Accuracy')
    axes[1, 0].set_ylabel('Accuracy')
    axes[1, 0].tick_params(axis='x', rotation=45)
    axes[1, 0].grid(True, alpha=0.3)
    
    for i, v in enumerate(accuracies):
        axes[1, 0].text(i, v + 0.01, f'{v*100:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # Casos cr√≠ticos detectados
    axes[1, 1].bar(model_names, casos, color='red', alpha=0.7)
    axes[1, 1].set_title(f'Casos Cr√≠ticos Detectados\n(Total: {criticos_reales:,})')
    axes[1, 1].set_ylabel('Casos Detectados')
    axes[1, 1].tick_params(axis='x', rotation=45)
    
    for i, v in enumerate(casos):
        pct = v / criticos_reales * 100 if criticos_reales > 0 else 0
        axes[1, 1].text(i, v + v*0.05, f'{v:,}\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('super_model_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úì Visualizaci√≥n guardada como 'super_model_results.png'")
    
    # 7. RESUMEN √âPICO FINAL
    print("\n" + "=" * 60)
    print("RESUMEN √âPICO - MODELO S√öPER AVANZADO")
    print("=" * 60)
    
    print(f"üèÜ MEJOR MODELO: {best_name}")
    print(f"üìä Accuracy: {best['accuracy']*100:.1f}%")
    print(f"üìä Recall-CR√çTICO: {best['recall_critico']*100:.1f}%")
    print(f"üìä Casos detectados: {criticos_detectados:,} de {criticos_reales:,}")
    
    print(f"\nüöÄ EVOLUCI√ìN COMPLETA DEL PROYECTO:")
    for name, acc, casos in evolution:
        pct = casos / criticos_reales * 100 if criticos_reales > 0 else 0
        if 'S√∫per' in name:
            print(f"   üèÜ {name}: {acc*100:.1f}% acc, {casos:,} casos ({pct:.1f}%)")
        else:
            print(f"   üìä {name}: {acc*100:.1f}% acc, {casos:,} casos ({pct:.1f}%)")
    
    # Mejoras incre√≠bles
    mejora_acc = (best['accuracy'] - 0.5652) / 0.5652 * 100
    
    print(f"\n‚úÖ MEJORAS INCRE√çBLES vs ORIGINAL:")
    print(f"   üöÄ Accuracy: +{mejora_acc:.1f}%")
    print(f"   üöÄ Casos cr√≠ticos: {criticos_detectados:,} vs 0 inicial")
    print(f"   üöÄ Recall cr√≠tico: {best['recall_critico']*100:.1f}% vs 0% inicial")
    
    print(f"\nüéØ CARACTER√çSTICAS QUE CAMBIARON TODO:")
    print("   TOP 3 que marcaron la diferencia:")
    for i, row in feature_importance.head(3).iterrows():
        print(f"   {i+1}. {row['Feature']}: {row['Importance']:.4f}")
    
    # Evaluaci√≥n final
    if criticos_detectados > 1000:
        print(f"\nüéâ ¬°INCRE√çBLE! >1000 casos cr√≠ticos detectados")
        print("   Este modelo puede salvar muchas vidas de animales")
    elif criticos_detectados > 500:
        print(f"\nüöÄ ¬°EXCELENTE! >500 casos cr√≠ticos detectados")
        print("   Rendimiento extraordinario para casos cr√≠ticos")
    elif criticos_detectados > 200:
        print(f"\nüëç ¬°MUY BUENO! >200 casos cr√≠ticos detectados")
        print("   Mejora sustancial en detecci√≥n cr√≠tica")
    else:
        print(f"\nüìà Progreso significativo: {criticos_detectados:,} casos detectados")
    
    print(f"\nüèÅ MISI√ìN CUMPLIDA:")
    print(f"   ‚úÖ Modelo s√∫per avanzado implementado")
    print(f"   ‚úÖ Caracter√≠sticas cr√≠ticas incorporadas")
    print(f"   ‚úÖ {criticos_detectados:,} casos cr√≠ticos detectables")
    print(f"   ‚úÖ Sistema listo para salvar vidas de animales")
    
    return best['model']

if __name__ == "__main__":
    model = main() 